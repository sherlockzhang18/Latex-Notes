\lesson{19}{Fri Oct 17 2025 15:00}{}

\dots

Taylor Expansion $ f $ about $ \xi $ ($ f(\xi) = 0 $)

\[
    f_{i}(\xi) = f_{i}(x) + \triangledown f_{i}(x) \cdot (\xi - x) + \frac{1}{2} \sum_{j = 1}^{n} \sum_{k = 1}^{n} \frac{\partial^2 f_{i}}{\partial x_{j} \partial x_{k}} (\eta_{i})(\xi_{j} - x_{j})(\xi_{k}-x_{k})
\]

with $ \eta  $ between $ \xi $ and $ x $.

\[
    \begin{bmatrix}
      \triangledown f_1 (x) \\
      \vdots \\
      \triangledown f_{n}(x) \\
    \end{bmatrix}
     = J_{f}(x)
\]


\[
    0 = f(\xi) = f(x) + J_{f}(x) \cdot (\xi - x) + \frac{1}{2} E_{f}(\xi,x)
\]

where
\[
    \left[E_{f}(\xi,x)\right] = \sum_{j = 1}^{n} \sum_{k = 1}^{n} \frac{\partial^2 f_{i}}{\partial x_{j} \partial x_{k}} (\eta_{i})(\xi_{j} - x_{j})(\xi_{k}-x_{k})
\]

so 
\[
    -f(x_{k}) = J_{f}(x_{k}) \cdot (\xi - x_{k}) + \frac{1}{2} E_{f}(\xi, x_{k})
\]
\[
    x_{k+1} = x_{k} - \left[ J_{f}(x_{k}) \right]^{-1} f(x_{k}) = \xi + \frac{1}{2} \left[J_{f}(x_{k})\right]^{-1} E_{f}(\xi,x_{k})
\]

\begin{theorem} convergence of Newtons' Method \leavevmode
    
    \begin{itemize}
        \item $ f: \mathbb{R}^n \to \mathbb{R}^n $
        \item $ f(\xi) = 0 $
        \item $ J_{f}(\xi) $ non-singular
        \item $ \frac{\partial^2 f_{i}}{\partial x_{j} \partial x_{k}} $ is continuous for all $ i, j, k $ in a neighbourhood of $ \xi $.
    \end{itemize}

    Then Newton's method converges if $ x_0 $ is sufficiently close to $ \xi $.

\end{theorem}

\vspace{1em}
\begin{proof} \leavevmode
    
    $ -f(x_{k}) = J_{f}(x_{k}) \cdot (\xi - x_{k}) + \frac{1}{2} E_{f}(\xi, x_{k}) $ holds for $ x \in \overline{B}_{\epsilon_1}(\xi) $ where $ \frac{\partial^2 f_{i}}{\partial x_{j} \partial x_{k}} $ continuous.

    \vspace{1em}
    \underbar{\textbf{Claim}}: $ J_{p}(x) $ is non-singular for all $ x \in \overline{B}_{\epsilon_2}(\xi) $, $ \epsilon_2 \leqslant \epsilon_1 $.

    \vspace{1em}
    $ \text{det}J_{f}(x) $ is a continuous function of $ x $, so if $ \text{det}J_{f}(x) \neq 0 $, then $ \exists \epsilon_2 $ such that $ \text{det}J_{f}(x) \neq 0 $ for all $ x \in \overline{B}_{\epsilon_2}(\xi) $.

    \vspace{1em}
    \begin{align*}
        \left\lVert x_{k+1} - \xi \right\rVert _\infty 
        &= \frac{1}{2} \left\lVert \left[J_{f}(x_{k})\right]^{-1} E_{f}(\xi,x_{k}) \right\rVert _\infty \\
        &\leqslant \frac{1}{2} \left\lVert \left[J_{f}(x_{k})\right]^{-1} \right\rVert _\infty \left\lVert E_{f}(\xi,x_{k}) \right\rVert _\infty \\
    \end{align*}

    now want $ \left\lVert \left[J_{f}(x_{k})\right]^{-1} \right\rVert _\infty \leqslant C $

    It is continuous function of x for all $ x \in \overline{B}_{\epsilon_3}(\xi), \epsilon_3 \leqslant \epsilon_2 $

    \vspace{1em}
    $ \left\lVert E_{f}(\xi,x_{k}) \right\rVert _\infty \leqslant A \left\lVert x_{k} - \xi \right\rVert _\infty^2 $ if $ x_{k} \in \overline{B}_{\epsilon_4}(\xi) $ with $ \epsilon_4 \leqslant \epsilon_3 $.

    So
    \begin{align*}
        \left\lVert x_{k+1} - \xi \right\rVert _\infty 
        &= \frac{1}{2} \left\lVert \left[J_{f}(x_{k})\right]^{-1} E_{f}(\xi,x_{k}) \right\rVert _\infty \\
        &\leqslant \frac{1}{2} \left\lVert \left[J_{f}(x_{k})\right]^{-1} \right\rVert _\infty \left\lVert E_{f}(\xi,x_{k}) \right\rVert _\infty \\
        &\leqslant \frac{1}{2}AC \left\lVert x_{k} - \xi \right\rVert _\infty \left\lVert x_{k} - \xi \right\rVert _\infty
    \end{align*}

    $ \frac{1}{2}AC \left\lVert x_{k} - \xi \right\rVert _\infty \leqslant L <1 $ if $ x_{k} \in \overline{B}_{\epsilon_5}(\xi) $ with $ \epsilon_5 \leqslant \min\{\epsilon_4, \frac{1}{AC}\} $

    \vspace{1em}
    So now we got
    \[
        \left\lVert x_{k+1} - \xi \right\rVert _\infty \leqslant L \left\lVert x_{k} - \xi \right\rVert _\infty \text{ if } x_0 \text{ is sufficiently close to } \xi
    \]

\end{proof}