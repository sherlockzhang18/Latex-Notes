\documentclass[a4paper]{article}

% \usepackage[margin=1in]{geometry} // reduce margin

% Basic packages
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{textcomp}
\usepackage{url}
\usepackage{booktabs}
\usepackage{enumitem}
\usepackage[dvipsnames]{xcolor}
\usepackage{xifthen}

% Math packages
\usepackage{amsmath, amsfonts, mathtools, amsthm, amssymb}
\usepackage{mathrsfs}
\usepackage{cancel}
\usepackage{bm}
\usepackage{systeme}
\usepackage{stmaryrd} % for \lightning

% Math shortcuts
\newcommand\N{\ensuremath{\mathbb{N}}}
\newcommand\R{\ensuremath{\mathbb{R}}}
\newcommand\Z{\ensuremath{\mathbb{Z}}}
\renewcommand\O{\ensuremath{\emptyset}}
\newcommand\Q{\ensuremath{\mathbb{Q}}}
\newcommand\C{\ensuremath{\mathbb{C}}}
\newcommand\F{\ensuremath{\mathbb{F}}}
\DeclareMathOperator{\sgn}{sgn}
\DeclareMathOperator{\Ker}{ker}
\DeclareMathOperator{\im}{Im}

% Logic symbols
\let\svlim\lim\def\lim{\svlim\limits}
\let\implies\Rightarrow
\let\impliedby\Leftarrow
\let\iff\Leftrightarrow
\let\epsilon\varepsilon
\newcommand\contra{\scalebox{1.1}{$\lightning$}}

% Useful commands
\definecolor{correct}{HTML}{009900}
\newcommand\correct[2]{\ensuremath{\:}{\color{red}{#1}}\ensuremath{\to }{\color{correct}{#2}}\ensuremath{\:}}
\newcommand\green[1]{{\color{correct}{#1}}}

% Horizontal rule
\newcommand\hr{
    \noindent\rule[0.5ex]{\linewidth}{0.5pt}
}

% Simple theorem environments (without fancy boxes for homework)
\theoremstyle{definition}
\newtheorem{definition}{Definition}
\newtheorem{theorem}{Theorem}
\newtheorem{lemma}{Lemma}
\newtheorem{proposition}{Proposition}
\newtheorem{corollary}{Corollary}
\newtheorem*{remark}{Remark}
\newtheorem*{note}{Note}
\newtheorem*{example}{Example}

% Problem environment
\newcounter{problem}
\newenvironment{problem}[1][]
{
    \stepcounter{problem}
    \section*{Problem \theproblem\ifx\relax#1\relax\else: #1\fi}
}
{}

% Subproblem environment
\newcounter{subproblem}[problem]
\newenvironment{subproblem}[1][]
{
    \stepcounter{subproblem}
    \subsection*{(\alph{subproblem})\ifx\relax#1\relax\else\ #1\fi}
}
{}

% Solution environment
\newenvironment{solution}
{
    \noindent\textbf{Solution:}\\
}
{
    
}

% Headers
\usepackage{fancyhdr}
\pagestyle{fancy}
\fancyhf{}
\fancyhead[L]{Sherlock Zhang}
\fancyhead[C]{4301 linear algebra - Homework 9}
\fancyhead[R]{\today}
\fancyfoot[C]{\thepage}

% Title info
\title{Math 4301 - Homework 9}
\author{Sherlock Zhang}
\date{\today}

\begin{document}

\maketitle

% =============================================================================
% HOMEWORK PROBLEMS START HERE
% =============================================================================

\begin{problem}[5B.1]

    Suppose $ T \in L(V) $. Prove that $ 9 $ is an eigenvalue of $ T^2 $ if and only if 3 or -3 is an eigenvalue of $ T $.

\end{problem}

\vspace{2em}
\begin{solution}

    $ \implies $

    Let $ v $ be the non-zero eigenvector of $ T^2 $ corresponding to 9. Then we have $ T^2 v = 9 v $, which shows $ (T^2 - 9I)(v) = 0 $. AS $ v $ is non-zero, $ T^2 - 9I $ is not injective. Since $ T^2 - 9I = (T - 3I)(T + 3I) $, then one of them must be not injective. So either 3 or -3 is an eigenvalue of $ T $ so that it can make $ T-3I $ or $ T + 3I $ not injective.

    \vspace{2em}
    $ \impliedby $ 

    Suppose $ v $ is a non-zero vector of $ T $ correspnding to the eigenvector 3 or -3, then $ Tv = 3v $ or $ Tv = -3v $. Then
    \[
        T^2v = T \circ T v = T(\pm3v) = \pm3T(v) = 9v
    \]
    
    Therefore, 9 is an eigenvector of $ T $.

\end{solution}

\newpage
\begin{problem}[5C.2]

    Suppose $ A $ and $ B $ are upper-triangular matrices of the same size, with $ \alpha_1, \cdots , \alpha_{n} $ on the diagonal of $ A $ and $ \beta_1, \cdots , \beta_{n} $ on the diagonal of $ B $.

\end{problem}

\begin{subproblem}

    Show that $ A + B $ is an upper-triangular matrix with $ \alpha_1 + \beta_1, \cdots , \alpha_{n} + \beta_{n} $ on the diagonal.

\end{subproblem}

\vspace{2em}
\begin{solution}

    \[
        (A + B)_{i,j} = A_{i,j} + B_{i,j} = 
        \begin{cases}
            \alpha_{i} + \beta_{i} \hspace{1em} &\text{if } i = j \\
            0    &\text{if } i > j
        \end{cases}
    \]

    Therefore, $ A + B $ is still upper-triangular with diagonal $ \alpha_1 + \beta_1, \cdots , \alpha_{n} + \beta_{n} $.
    
\end{solution}

\begin{subproblem}

    Show that $ AB $ is an upper-triangular matrix with $ \alpha_1\beta_1, \cdots , \alpha_{n}\beta_{n} $ on the diagonal.

\end{subproblem}

\vspace{2em}
\begin{solution}

    \[
        (AB)_{j,j} = \sum_{r=1}^{n}  A_{j,r}B_{r,j} = A_{j,j}B_{j,j} + \sum_{r \neq j}^{n} A_{j,r}B_{r,j} = \alpha_{j}\beta_{j} + \sum_{r \neq j}^{n} A_{j,r}B_{r,j}
    \]

    if $ r \neq j $, then either $ j > r $ or $ j <r $. If $ j > r $, then $ A_{j,r} = 0 $. If $ j < r $, $ B_{r,j} = 0 $. Then
    \[
        \sum_{r \neq j}^{n} A_{j,r}B_{r,j} = 0
    \]

    For non-diagonal entries, 
    \[
        (AB)_{j,k} = \sum_{r=1}^{n} A_{j,r}B_{r,k} = \sum_{r=1}^{j-1} A_{j,r}B_{r,k} + \sum_{r = j}^{n} A_{j,r}B_{r,k}
    \]

    If $ r \leqslant j - 1 $, then $ j > r $. Thus $ A_{j,r} = 0 $. $ \sum_{r=1}^{n} A_{j,r}B_{r,k} = 0 $.
    If $ j \leqslant r \leqslant n $, then $ r\geqslant  j > k $. Thus $ B_{r,k} = 0 $. $ \sum_{r=1}^{n} A_{j,r}B_{r,k} = 0 $.

    So $ (AB)_{j,k} = 0 $. This is equivalent to $ AB $ is upper-triangular with 
    
    $ \alpha_1\beta_1, \cdots , \alpha_{n}\beta_{n} $ on the diagonal.
    
\end{solution}


\newpage
\begin{problem}[5C.3]

    Suppose $ T \in L(V) $ is invertible and $ v_1,\cdots , v_{n} $ is a basis of $ V $ with respect to which the matrix of $ T $ is upper triangular, with $ \lambda_1, \cdots , \lambda_{n} $ on the diagonal. Show that the matrix of $ T^{-1} $ is also upper triangular with respect to the basis $ v_1, \cdots , v_{n} $, with 
    \[
        \frac{1}{\lambda_1}, \cdots \frac{1}{\lambda_{n}}
    \]
    on the diagonal.

\end{problem}

\vspace{2em}
\begin{solution}

    Since $ M(T) $ is upper-triangular, $ \lambda_1 $ is the eigenvalue. Then, we know that $ Tv_1 = \lambda_1v_1 $. From previous homework problme we know that $ Tv_1 = \lambda_1v_1 \implies T^{-1}v_1 = \lambda_1^{-1}v_1 $. Therefore, the first entry of $ M(T^{-1}) $ is $ \lambda^{-1} $.

    \vspace{1em}
    $ Tv_2 = u + \lambda_2v_2 $ where $ u \in \text{span }(v_1) $. This shows that $ T^{-1}v_2  = \lambda_2^{-1}T^{-1}u + \lambda_2^{-1}v_2 $. $ \lambda_2^{-1}T^{-1}u $ is in span $ v_1 $ as it is invariant under $ T^{-1} $. Therefore, $ T^{-1}v_2 \in \text{span }(v_1, v_2) $. Therefore, $ \text{span }(v_1, v_2) $ is also invariant under $ T^{-1} $. 

    \vspace{1em}
    Continuing in this constructive process we will get that $ \text{span }(v_1, \cdots ,v_{k}) $ is invariant under $ T^{-1} $, so that $ M(T^{-1}) $ is upper-triangular with $ \frac{1}{\lambda_1}, \cdots \frac{1}{\lambda_{n}} $ on the diagonal.
    
\end{solution}

\newpage
\begin{problem}[5C.4]

    Give an example of an operator whose matrix with respect to some basis contains only 0's on the diagonal, but the operator is invertible.

\end{problem}

\vspace{2em}
\begin{solution}

    The rotational matrix by 180 degree in $ \mathbb{R}^2 $, which is 
    \[
        M(T) = \begin{bmatrix}
          0 & 1 \\
          1 & 0 \\
        \end{bmatrix}
    \]

    is invertible since $ T^2 = I $.
    
\end{solution}

\newpage
\begin{problem}[5C.5]

    Give an example of an operator whose matrix with respect to some basis contains only nonzero numbers on the diagonal, but the operator is not invertible.

\end{problem}

\vspace{2em}
\begin{solution}

    Assume 
    \[
        M(T) = \begin{bmatrix}
          1 & 1 \\
          1 & 1 \\
        \end{bmatrix}
    \]
    which is the same as $ T(x, y) = (x+y, x+y) $. It is not invertible as $ T(1, -1) = 0 $ so $ T $ is not injective.
    
\end{solution}

\newpage
\begin{problem}[5C.6]

    Suppose $ F = \mathbb{C} $, $ V $ is finite-dimensional, and $ T \in L(V) $. Prove that if $ k \in \{1, \cdots , \dim V\} $, then $ V $ has a $ k $-dimensional subspace invariant under $ T $.

\end{problem}

\vspace{2em}
\begin{solution}

    Let $ \dim V = n $.

    \vspace{1em}
    By the therem covered in class there exists a basis $ v_1, \cdots , v_{n} $ such that $ M(T) $ is upper triangular. 
    
    \vspace{1em}
    By another theorem covered in class, if $ M(T) $ is upper-triangular, it is equivalent to say that $ \text{span }(v_1, \cdots ,v_{k}) $ is invariant under $ T $ for each $ k = 1, \cdots , n$. 
    
\end{solution}

\newpage
\begin{problem}[5C.10]

    Suppose $ T \in L(V) $ and $ v_1, \cdots , v_{n} $ is a basis of $ V $. Show that the following are equivalent.
    \begin{itemize}
        \item The matrix of $ T $ with respect to $ v_1, \cdots , v_{n} $ is lower triangular.
        \item $ \text{span }(v_{k}, \cdots ,v_{n}) $ is invariant under $ T $ for each $ k = 1, \cdots , n $.
        \item $ Tv_{k} \in \text{span }(v_{k}, \cdots ,v_{n}) $ for each $ k = 1, \cdots , n $.
    \end{itemize}

\end{problem}

\vspace{2em}
\begin{solution}

    (a) $\iff$ (c)

    \vspace{0.5em}
    Suppose the matrix of $T$ with respect to $v_1,\ldots,v_n$ is lower triangular.  
    This means in the expression for $T(v_k)$, all coefficients of $v_1,\ldots,v_{k-1}$ are zero.  
    So $T(v_k)$ looks like
    \[
        T(v_k) = a_{k,k} v_k + a_{k+1,k} v_{k+1} + \cdots + a_{n,k} v_n,
    \]
    and therefore $T(v_k) \in \text{span}(v_k,\ldots,v_n)$, which is equivalent (c).

    \vspace{1em}

    Conversely, if $T(v_k)$ is always in $\text{span}(v_k,\ldots,v_n)$, then $T(v_k)$ has no components along $v_1,\ldots,v_{k-1}$.  
    That means the first $k-1$ entries in the $k$-th column of the matrix are zero, so the matrix is lower triangular.  
    This gives (a).

    \vspace{2em}

    (b) $\iff$ (c)

    \vspace{0.5em}
    If $\text{span}(v_k,\ldots,v_n)$ is invariant under $T$, then in particular $v_k$ is in that span, so applying $T$ gives  
    $T(v_k) \in \text{span}(v_k,\ldots,v_n)$, which is (c).

    \vspace{1em}

    Conversely, if (c) holds, then for any  
    $w = a_k v_k + \cdots + a_n v_n \in \text{span}(v_k,\ldots,v_n)$,  
    we get
    \[
        T(w) = a_k T(v_k) + \cdots + a_n T(v_n),
    \]
    and by (c) each $T(v_j)$ stays inside $\text{span}(v_k,\ldots,v_n)$.  
    So the whole subspace is invariant, which is (b).

\end{solution}

\newpage
\begin{problem}[5D.3]

    Suppose $ V $ is finite-dimensional and $ T \in L(V) $. Prove that if the operator $ T $ is diagonalizable, then $ V = \text{null }T \oplus \text{range }T $.

\end{problem}

\vspace{2em}
\begin{solution}

    Let $\lambda_1,\ldots,\lambda_m$ be all the nonzero eigenvalues of $T$ (there may be none).  
    From a theorem covered in class, we know that $V$ can be shown as
    \[
        V = E(0,T) \oplus E(\lambda_1,T) \oplus \cdots \oplus E(\lambda_m,T).
    \]
    Since $E(0,T) = \text{null }T$, we can rewrite this as  
    $V = \text{null }T \oplus W$,  
    where $W = E(\lambda_1,T) \oplus \cdots \oplus E(\lambda_m,T)$ (and if there are no nonzero eigenvalues, we just let $W=\{0\}$).

    Now suppose we take some $Tv$ in $\text{range }T$.  
    From the direct-sum decomposition, $v$ can be written as  
    $v = u + w_1 + \cdots + w_m$  
    with $u \in \text{null }T$ and $w_k \in E(\lambda_k,T)$.  
    Applying $T$ gives
    \[
        T v = \lambda_1 w_1 + \cdots + \lambda_m w_m,
    \]
    which clearly lies in $W$.  
    So we have $\text{range }T \subseteq W$.

    On the other hand, let $w_1 + \cdots + w_m \in W$.  
    Since each $\lambda_k \neq 0$, we can reverse $T$ on each eigenvector:
    \[
        w_1 + \cdots + w_m 
        = T\big( \lambda_1^{-1} w_1 + \cdots + \lambda_m^{-1} w_m \big).
    \]
    Thus every element in $W$ actually comes from applying $T$ to something.  
    So $W \subseteq \text{range }T$.

    So $W = \text{range }T$.  
    Since $V = \text{null }T \oplus W$, we know that
    \[
        V = \text{null }T \oplus \text{range }T.
    \]

\end{solution}



\end{document}
