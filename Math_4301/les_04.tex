\lesson{4}{Thr Sep 4 2025 14:30}{}

\vspace{1em}
\begin{eg}
    Span $ \left((1,0,0) , (1,2,1)\right) = \{(a+b, 2b. b) | a,b \in \mathbb{R}\} $ in $ \mathbb{R}^3 $
\end{eg}

\begin{prop}
    If $ W = \text{ span} (v_1, \cdots , v_n) $, then $ W $ is the smallest subspace of $ V $ containing $ v_1, \cdots , v_n $.
\end{prop}

\vspace{1em}
\begin{proof}\leavevmode

    $ v_i = 0v_{1} + \cdots + 1v_i + \cdots + 0 v_m $, so $ v_i \in \text{span}(v_1, \cdots , v_m) $ for every $ i $.

    \begin{itemize}
    \item span $ (v_1, \cdots ,v_m) $ is a subspace.
    \begin{itemize}
        \item $ 0 = 0v_1 + \cdots  + 0v_n $
        \item $ (a_1v_1 + \cdots +a_mv_m) + (b_1v_1 + \cdots +b_mv_m) = (a_1+b_1, \cdots , a_m+b_m)v_m $
        \item $ c(a_1v_1 + \cdots +a_m v_m) = (ca_1)v_1 + \cdots +(ca_m)v_m $
    \end{itemize}

    \item If $ W \subset V $ is a subspace and $ v_1, \cdots ,v_m \in W$, then $ a_1v_1+ \cdots + a_mv_m \in W $ for all $ a_1, \cdots , a_m \in F $. so span $ (v_1, \cdots , v_m)  \subseteq W$
\end{itemize}

\end{proof}


\vspace{2em}
\begin{definition} Linearly Independency \leavevmode

    A list $ v_1, \cdots , v_m $is called linearly independent if $ a_1v_1+ \cdots  + a_nv_n = 0 $ implies $ a_1 = \cdots =a_m = 0 $. Otherwise, it is linearly dependent.
\end{definition}

\vspace{1em}
\begin{eg}
    $ (1,0,1),(-2, 1, 1), (0,1,3) $ linearly dependent.
    \[
        -2(1,0,1)-(-2,1,1) + (0,1,3) = 0
    \]
\end{eg}

\begin{remark} \leavevmode
    \begin{itemize}
        \item If $ v $ is a list of length 1, then $ v $ is linearly independent exactly when $ v \neq 0 $
        \item if $ v_1, v_2 $ is a list of length 2, then it is linearly independent exactly when $ v_1, v_2 \neq 0 $ and $ v_1 $ is not a scalar multiple of $ v_2 $.
        
        \begin{explanation}
            exercise
        \end{explanation}

        \item By convention span$ () = \{0\} $ (empty list). Empty list is linearly independent.
    \end{itemize}
\end{remark}


\vspace{1em}
\begin{lemma} \underbar{\textbf{Linear Dependence Lemma}} \leavevmode

    \noindent Let $ v_1, \cdots , v_m $ be linearly dependent. There exist $ j $ such that:
    \begin{enumerate}
        \item $ v_j \in \text{span}(v_1, \cdots ,v_{j-1}) $
        \item $ \text{span}(v_1, \cdots , v_{j-1}, v_{j+1}, \cdots , v_m) = \text{span}(v_1, \cdots , v_j, \cdots , v_m) $
    \end{enumerate}
\end{lemma}

\begin{proof}
    There are $ a_1, \cdots , a_m $ not all 0 with
    \[
        a_1v_1 + \cdots + a_mv_m = 0
    \]

    Let $ j $ be the largest index such that $ a_j \neq 0 $. Then,
    \begin{align*}
        &a_1v_1 + \cdots + a_jv_j = 0 \hspace{2em} a_j\neq 0 \\
        \implies & a_jv_j = -a_1v_1 \cdots -a_{j-1}v_{j-1} \\
        \implies & v_j = \frac{-a_1}{a_j}v_{1} + \cdots +\frac{-a_{j-1}}{a_j} v_{j-1} \\
        \implies & v_j \in \text{ span}(v_1, \cdots , v{j-1})
    \end{align*}

    Claim: span $ (v_1, \cdots ,v{j-1}, v{j+1}, \cdots ,v_m) = \text{span}(v_1, \cdots ,v_j, \cdots , v_m)$

    \vspace{1em}
    $ \subseteq $ direction is quite clear

    \vspace{1em}
    $ \supseteq $: if
    \begin{align*}
        u =& b_1v_1 + \cdots + v_{j-1}v_{j-1} + b_jv_j + b_{j+1}v_{j+1} + \cdots +b_mv_m\\
        =& b_1v_1 + \cdots + b_{j-1}v_{j-1} + \left(\frac{-a_1b_j}{a_j}v_1 + \cdots +\frac{-a_{j-1}b_j}{a_j}v_j\right) + \\
        & b_{j+1}v_{j+1} \cdots  + b_mv_m \in \text{span}(v_1, \cdots , v_{j-1}, v_{j+1}, \cdots , v_m)
    \end{align*}

\end{proof}

\vspace{2em}
\begin{definition} \leavevmode

    \noindent A vector space $ V $ is called \underbar{finite dimentional} if there is a list $ v_1, \cdots ,v_m $ of vectors in $ V $ such that span$ (v_1, \cdots ,v_m) = V$.

    \vspace{1em}
    \noindent Otherwise we call it \underbar{Infinite Dimensional}.
\end{definition}

\begin{eg} \leavevmode

    \begin{enumerate}
        \item $ F^n $ is finite dimensional.

        $ v_i  = (0, \cdots , 1, \cdots , 0) $ (1 at the ith place) $ i = 1, \cdots , n $. 
        
        Then span$ (v_1, \cdots ,v_n) = F^n $

        \item infinite dimensinoal:
        \begin{itemize}
            \item vector space of continuous functions $ f: \mathbb{R} \to \mathbb{R} $
            \item $ P(F) =  $ vector space of polynomial with coefficients from $ F $. $ V = \{a_dx^d + \cdots +a_1x + a_0\} $.
            
            If $ P_1, \cdots P_m \in V $ and if $ d_i =  $ degree of $ P_i $. Choose $ d $ with $ d > \text{max}(d_1, \cdots , d_m) $, then $ x^d \notin \text{span}(P_1, \cdots , p_m) $. 
            
            So span$ (P_1, \cdots ,P_m) \neq P(F) $
        \end{itemize}
    \end{enumerate}
    
\end{eg}


\section{Bases}
\begin{definition}
    A \underbar{basis} is a list of vectors $  v_1, \cdots , v_m $ such that:
    \begin{enumerate}
        \item $ v_1, \cdots ,v_m $ are linearly independent.
        \item $ v_1, \cdots ,v_m $ spans $ V $. $ V = \text{span}(v_1, \cdots , v_m) $
    \end{enumerate}
\end{definition}

\vspace{1em}
\begin{eg}
    \begin{enumerate}
        \item $ F^n $: $ e_i = (0, \cdots , 1, \cdots ,0) $ (with 1 at the ith place).
        Then $ e_1, \cdots ,e_n $ is a basis for $ F^n $. A standard basis.

        \item $ \mathbb{R}^2 $: $ (1,0), (0,1) $ standard basis. $ (1,0), (-2,1) $ also a basis. 
        
        ($ (x,y) = (x+2y)(1,0) -y(2, -1) $)
    \end{enumerate}
\end{eg}

\begin{theorem}
    $ v_1, \cdots , v_m $ is a basis for $ V $ if and only if every vector $ v $ in $ V $ can be written \underbar{\textbf{uniquely}} as a linear combinations.
    \[
        v = a_1v_1 + \cdots + a_m v_m
    \]
\end{theorem}

\vspace{1em}
\begin{proof}\leavevmode

    $ \implies $

    \[
        v = a_1v_1 + \cdots + a_mv_m = b_1v_1 + \cdots + b_mv_m
    \]

    Then, $ (b_1-a_1)v_1 + \cdots (b_m-a_m)v_m = 0 $. So $ b_i-a_i = 0 $ for all $ i $. So $ a_i = b_i $ for all $ i $.

    \vspace{2em}
    $ \impliedby $ Spanning clearly holds.

    Want to prove linear independence:

    If $ c_1v_1 + \cdots + c_mv_m = 0 $, then
    \[
        c_1v_1 + \cdots + c_mv_m = 0v_1 + \cdots +0v_m
    \]
    By uniqueness, $ c_1 = 0, c_2 = 0, \cdots , c_m = 0 $
\end{proof}

$ v_1, \cdots , v_m $: basis, $ v \in V $, then $ v = a_1v_1 + \cdots + a_mv_m $ uniquely. $ a_1, \cdots , a_m $ are the coordinates (of $ v $ with respect to the basis). 


\vspace{2em}
\begin{prop} \leavevmode

    Every \underbar{spanning list} (i.e. $ v_1, \cdots , v_m $ such that $ V = \text{span}(v_1, \cdots , v_m) $) can be reduced to a basis.
    
\end{prop}

\begin{proof}
    Let $ v_1, \cdots ,v_{n} $ be spanning: $  V = \text{span}(v_1, \cdots ,v_{n}) $. If $ v_1, \cdots , v_{n} $ is linearly independent, we are done. Otherwise, by the linear dependence lemma, there is $ j $ such that
    \[
        \text{span}(v_1, \cdots , v_{j-1}, v_{j+1}, \cdots , v_{n}) = \text{span}(v_1, \cdots , v_{n}) = V
    \]

    Now consider $ v_1, \cdots , v_{j-1}, v_{j+1}, \cdots , v_{n} $. If this list is linearly independent, it is a basis. Otherwise, apply the linear dependence lemma again to remove any more vector and continue. By continuing we get to a basis.
\end{proof}

\begin{corollary}
    Every finite-dimensional vector space has a basis.
\end{corollary}

\begin{proof}\leavevmode
    
    $ V $ finite-dimensional. so $ V = \text{span}(v_1, \cdots , v_{n}) $ for some list $ v_1, \cdots , v_{n} $. By the proposition $ v_1, \cdots , v_{n} $ can be reduced to a basis.
\end{proof}